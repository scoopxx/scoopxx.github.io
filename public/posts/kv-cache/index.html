<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>KV Cache Explained | Log(hx)</title>
<meta name="keywords" content="vllm, KV Cache, transformer">
<meta name="description" content="What is KV Cache?
I am not intended to spend too much time on details of KV cache. But as a reference, I found the interpretation in this this post Transformers KV Caching Explained very intuitive, so I&rsquo;ll just steal the gif here.

To summarize, in auto-regressive language model,when generating a new token, all its previous tokens are fed into the attention layer for computation. In an attention layer, denote the text input/generation sequence as $X$, where as $i$ th token is $x_i$. When in step $i$, we are predicting $X_i$, the formula is:
$$
q_{i} = embed_i * W_q \quad(1, d_{model})
$$
$$
k_{i} = embed_i * W_k \quad(1, d_{model})
$$
$$
v_{i} = embed_i * W_v \quad(1, d_{model})
$$
$$
K = concat(k_{0}, k_{1}, &hellip;, k_{i})  \quad(i&#43;1, d_{model})
$$
$$
Attn = softmax(q_{i} * K^T / \sqrt{d_{model}}) \quad(1, i&#43;1)
$$
$$
Output = Attn * [v_{0}, v_{1}, &hellip;, v_{i}]  \quad(1, d_{model})
$$">
<meta name="author" content="hxx">
<link rel="canonical" href="http://localhost:1313/posts/kv-cache/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.519db25830472c2083527875996b96dafffe4841e99170caece374d56241122a.css" integrity="sha256-UZ2yWDBHLCCDUnh1mWuW2v/&#43;SEHpkXDK7ON01WJBEio=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/kv-cache/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" onload="
  renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false},
      {left: '\\(', right: '\\)', display: false},
      {left: '\\[', right: '\\]', display: true}
    ],
    throwOnError: false
  });
"></script>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Log(hx) (Alt + H)">Log(hx)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      KV Cache Explained
    </h1>
    <div class="post-meta"><span title='2025-03-03 00:00:00 +0000 UTC'>March 3, 2025</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;hxx

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#what-is-kv-cache" aria-label="What is KV Cache?">What is KV Cache?</a></li>
                <li>
                    <a href="#how-many-flops-are-saved-by-kv-cache" aria-label="How many FLOPs are saved by KV Cache?">How many FLOPs are saved by KV Cache?</a><ul>
                        
                <li>
                    <a href="#total-flops-without-kv-cache" aria-label="Total flops without KV Cache:">Total flops without KV Cache:</a></li>
                <li>
                    <a href="#flops-with-addtional-kv-cache" aria-label="Flops with addtional KV Cache:">Flops with addtional KV Cache:</a></li></ul>
                </li>
                <li>
                    <a href="#flops-calculation-with-an-example" aria-label="FLOPs calculation with an example">FLOPs calculation with an example</a></li>
                <li>
                    <a href="#test-kv-cache-in-huggingfaces-transformers" aria-label="Test KV Cache in Huggingface&rsquo;s transformers">Test KV Cache in Huggingface&rsquo;s transformers</a></li>
                <li>
                    <a href="#a-brief-peek-into-transformers-kv-cache-implementation" aria-label="A brief peek into transformer&rsquo;s KV Cache implementation">A brief peek into transformer&rsquo;s KV Cache implementation</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="what-is-kv-cache">What is KV Cache?<a hidden class="anchor" aria-hidden="true" href="#what-is-kv-cache">#</a></h3>
<p>I am not intended to spend too much time on details of KV cache. But as a reference, I found the interpretation in this this post <a href="https://medium.com/@joaolages/kv-caching-explained-276520203249">Transformers KV Caching Explained</a> very intuitive, so I&rsquo;ll just steal the gif here.</p>
<p><img alt="Comparison of self-attention with and without KV attention" loading="lazy" src="/images/kv-cache.gif"></p>
<p>To summarize, in auto-regressive language model,when generating a new token, all its previous tokens are fed into the attention layer for computation. In an attention layer, denote the text input/generation sequence as $X$, where as $i$ th token is $x_i$. When in step $i$, we are predicting $X_i$, the formula is:
$$
q_{i} = embed_i * W_q \quad(1, d_{model})
$$
$$
k_{i} = embed_i * W_k \quad(1, d_{model})
$$
$$
v_{i} = embed_i * W_v \quad(1, d_{model})
$$
$$
K = concat(k_{0}, k_{1}, &hellip;, k_{i})  \quad(i+1, d_{model})
$$
$$
Attn = softmax(q_{i} * K^T / \sqrt{d_{model}}) \quad(1, i+1)
$$
$$
Output = Attn * [v_{0}, v_{1}, &hellip;, v_{i}]  \quad(1, d_{model})
$$</p>
<p>As we can see, at step $i$, its output is computed using that step&rsquo;s query $q_{i}$, as well as keys and values of all tokens up to $i$. So the intuition of KV Cache pretty straightforward: to store keys and values of all tokens up to $i$, so to avoid execssive computation during matrix multiplications.</p>
<h3 id="how-many-flops-are-saved-by-kv-cache">How many FLOPs are saved by KV Cache?<a hidden class="anchor" aria-hidden="true" href="#how-many-flops-are-saved-by-kv-cache">#</a></h3>
<p>Let&rsquo;s run an analysis on the FLOPs of attention layer.</p>
<blockquote>
<p><strong>FLOPs for matrix multiplication:</strong></p>
<p>If we are doing matrix multiplication between matrices of respective size of $(m, n)$ and $(n, p)$:</p>
<ol>
<li>A signle multiplication is 1 operation.</li>
<li>A single addition is 1 operation.</li>
<li>Computing element at $(i, j)$ would take n multiplcaitions and (n-1)
addtions, in total $2n - 1$ operations.</li>
</ol>
<p>The output is a matrix of size $(m,p)$, and total operations is $(2n-1) * m * p$,
we ignore the $-1$ notion for simplicity, so in total $2mnp$ operations.</p></blockquote>
<p>Assuming we have GPT model with $n$ layers, each transformer block has $k$ heads. The model dimension is $d_{model}$, and each head has $d_{model} / k$ dimension. Assuming we are doing batch inference on $b$ samples with sequence length $s$.</p>
<h4 id="total-flops-without-kv-cache">Total flops without KV Cache:<a hidden class="anchor" aria-hidden="true" href="#total-flops-without-kv-cache">#</a></h4>
<p><strong>1. Embedding Lookup</strong>  <br>
This part does not has arithmetic operations, only table lookups, ignore it.</p>
<p><strong>2. Self-Attention</strong>    <br>
For a self attention layer, at step $i$,</p>
<ol>
<li>Compute $Q$: compute $q_i$ only, $2b * d_{model}^2$ FLOPs.
$$
(b, 1, d_{model}) . (d_{model}, d_{model}) = (b, 1, d_{model})
$$</li>
<li>Compute $K$: compute $k_{0-&gt;i}$, $2b * i * d_{model}^2$ FLOPs.
$$
(b, i, d_{model}) . (d_{model}, d_{model}) = (b, i, d_{model})
$$</li>
<li>Compute $V$: similar to step 2, $2b * i * d_{model}^2$ FLOPs</li>
<li>$QK^T$, $2b * i * d_{model}$ FLOPs.
$$
(b, 1, d_{model}) . (b, i, d_{model}) = (b, 1, i)
$$</li>
<li>Weighted Value $attn*V$: $2b * i * d_{model}$ FLOPs.
$$
(b, 1, i) . (b, i, d_{model}) = (b, 1, d_model)
$$</li>
<li>Linear projection: $2b * d_{model}^2$ FLOPs.
$$
(b, 1, d_{model}) . (d_{model}, d_{model}) = (b, 1, d_{model})
$$</li>
</ol>
<p><strong>3. MLP</strong><br>
There are two matrix multiplications in MLP, each with $8b*d_{model}^2$ FLOPs.</p>
<p>$$
(b, 1, d_{model}) . (d_{model}, 4d_{model}) = (b, 1, 4d_{model})
$$
$$
(b, 1, 4d_{model}) . (4d_{model}, d_{model}) = (b, 1, d_{model})
$$</p>
<p><strong>4. Final projection layer</strong>
The final layer is to project the output to vocab size $V$, which is $2b * d_{model}* V$ FLOPs.
$$
(b, 1, d_{model}) . (d_{model}, V) = (b, 1, V)
$$</p>
<p>To sum these numbers up, as well as integral $i$ over $[1, s]$, in a GPT with $L$ layers, we have total flops:</p>
<p>$$
FLOPs = (2b * d_{model}^2 * s^2 + 20b * d_{model}^2 * s) * L + 2b * d_{model} * V * s
$$</p>
<h4 id="flops-with-addtional-kv-cache">Flops with addtional KV Cache:<a hidden class="anchor" aria-hidden="true" href="#flops-with-addtional-kv-cache">#</a></h4>
<p>When KV Cache is used, the main optimization happened when computing $K$ and $V$ in self attention layer. Instead of doing matrix multiplication to compute $K_{j \in [0, i]}$ and $V_{j \in [0, i]}$, we cached and fetched $K_{j \in [0, i-1]}$ and $V_{j \in [0, i-1]}$, and only compute $K_j$ and $V_j$.    <br>
The FLOPs at step $i$ is reduced from $2b \times d_{model}^2 \times i$ to $2b \times d_{model}^2 $. Integral over $i$, th quaratic part of $s$ decreasefrom $2bd_{model}^2s^2$ to $4bd_{model}^2s$.</p>
<p>The total FLOPs becomes:</p>
<p>$$
FLOPs_{sum_{i=1}^s} = (24b * d_{model}^2 * s) * L + 2b * d_{model} * V * s
$$</p>
<p>Without KV Cache, the operations scaled quadratically with the sequence length $s$. With KV Cache, the operations scale linearly with $s$, which makes it more efficient for longer sequences.</p>
<h3 id="flops-calculation-with-an-example">FLOPs calculation with an example<a hidden class="anchor" aria-hidden="true" href="#flops-calculation-with-an-example">#</a></h3>
<p>Let&rsquo;s look at the FLOPs calculation using GPT3-medium as an example. Say we have:
$$
d_{model} = 1024, L = 24, V = 50257
$$</p>
<table>
  <thead>
      <tr>
          <th>Sequence Length (s)</th>
          <th>Without KV Cache</th>
          <th>With KV Cache</th>
          <th>Reduction Percentage</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>10</td>
          <td>$1.11 \times 10^{10}$</td>
          <td>$7.07 \times 10^9$</td>
          <td>36.29%</td>
      </tr>
      <tr>
          <td>100</td>
          <td>$5.64 \times 10^{11}$</td>
          <td>$7.07 \times 10^{10}$</td>
          <td>87.46%</td>
      </tr>
      <tr>
          <td>500</td>
          <td>$1.29 \times 10^{13}$</td>
          <td>$3.53 \times 10^{11}$</td>
          <td>97.26%</td>
      </tr>
      <tr>
          <td>1000</td>
          <td>$5.09 \times 10^{13}$</td>
          <td>$7.07 \times 10^{11}$</td>
          <td>98.61%</td>
      </tr>
      <tr>
          <td>2000</td>
          <td>$2.03 \times 10^{14}$</td>
          <td>$1.41 \times 10^{12}$</td>
          <td>99.30%</td>
      </tr>
      <tr>
          <td>4000</td>
          <td>$8.08 \times 10^{14}$</td>
          <td>$2.83 \times 10^{12}$</td>
          <td>99.65%</td>
      </tr>
      <tr>
          <td>8000</td>
          <td>$3.23 \times 10^{15}$</td>
          <td>$5.66 \times 10^{12}$</td>
          <td>99.82%</td>
      </tr>
  </tbody>
</table>
<h3 id="test-kv-cache-in-huggingfaces-transformers">Test KV Cache in Huggingface&rsquo;s transformers<a hidden class="anchor" aria-hidden="true" href="#test-kv-cache-in-huggingfaces-transformers">#</a></h3>
<p>We can test the effectiveness of KV Cache using <a href="https://github.com/huggingface/transformers/tree/main">huggingface&rsquo;s transformers</a>.</p>
<div class="highlight"><div style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#859900">def</span> <span style="color:#268bd2">test_transformer_kv_cache</span>(<span style="color:#268bd2">model_name</span>=<span style="color:#2aa198">&#34;gpt2&#34;</span>, <span style="color:#268bd2">prompt</span>=<span style="color:#2aa198">&#34;Hello, I&#39;m a language model&#34;</span>, 
</span></span><span style="display:flex;"><span>                             <span style="color:#268bd2">num_new_tokens</span>=<span style="color:#2aa198;font-weight:bold">50</span>, <span style="color:#268bd2">num_runs</span>=<span style="color:#2aa198;font-weight:bold">5</span>, <span style="color:#268bd2">use_gpu</span>=<span style="color:#859900;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#dc322f;font-weight:bold">import</span> <span style="color:#268bd2">time</span>
</span></span><span style="display:flex;"><span>    <span style="color:#dc322f;font-weight:bold">import</span> <span style="color:#268bd2">torch</span>
</span></span><span style="display:flex;"><span>    <span style="color:#dc322f;font-weight:bold">from</span> <span style="color:#268bd2">transformers</span> <span style="color:#dc322f;font-weight:bold">import</span> <span style="color:#268bd2">AutoModelForCausalLM</span>, <span style="color:#268bd2">AutoTokenizer</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">device</span> = <span style="color:#2aa198">&#34;cuda&#34;</span> <span style="color:#859900">if</span> <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">cuda</span>.<span style="color:#268bd2">is_available</span>() <span style="color:#859900">and</span> <span style="color:#268bd2">use_gpu</span> <span style="color:#859900">else</span> <span style="color:#2aa198">&#34;cpu&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Using device: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">device</span><span style="color:#2aa198">}</span><span style="color:#2aa198">&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#93a1a1;font-style:italic"># Load model and tokenizer</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">model</span> = <span style="color:#268bd2">AutoModelForCausalLM</span>.<span style="color:#268bd2">from_pretrained</span>(<span style="color:#268bd2">model_name</span>).<span style="color:#268bd2">to</span>(<span style="color:#268bd2">device</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">tokenizer</span> = <span style="color:#268bd2">AutoTokenizer</span>.<span style="color:#268bd2">from_pretrained</span>(<span style="color:#268bd2">model_name</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#93a1a1;font-style:italic"># Tokenize input</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">input_ids</span> = <span style="color:#268bd2">tokenizer</span>(<span style="color:#268bd2">prompt</span>, <span style="color:#268bd2">return_tensors</span>=<span style="color:#2aa198">&#34;pt&#34;</span>).<span style="color:#268bd2">input_ids</span>.<span style="color:#268bd2">to</span>(<span style="color:#268bd2">device</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">input_length</span> = <span style="color:#268bd2">input_ids</span>.<span style="color:#268bd2">shape</span>[<span style="color:#2aa198;font-weight:bold">1</span>]
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">results</span> = {
</span></span><span style="display:flex;"><span>        <span style="color:#2aa198">&#34;with_kv_cache&#34;</span>: [],
</span></span><span style="display:flex;"><span>        <span style="color:#2aa198">&#34;without_kv_cache&#34;</span>: []
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Running inference with model: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">model_name</span><span style="color:#2aa198">}</span><span style="color:#2aa198">&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Input prompt: &#39;</span><span style="color:#2aa198">{</span><span style="color:#268bd2">prompt</span><span style="color:#2aa198">}</span><span style="color:#2aa198">&#39; (Length: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">input_length</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> tokens)&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Generating </span><span style="color:#2aa198">{</span><span style="color:#268bd2">num_new_tokens</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> new tokens, averaging over </span><span style="color:#2aa198">{</span><span style="color:#268bd2">num_runs</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> runs</span><span style="color:#2aa198">\n</span><span style="color:#2aa198">&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#859900">for</span> <span style="color:#268bd2">use_kv_cache</span> <span style="color:#859900">in</span> [<span style="color:#859900;font-weight:bold">False</span>, <span style="color:#859900;font-weight:bold">True</span>]:
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">cache_status</span> = <span style="color:#2aa198">&#34;with&#34;</span> <span style="color:#859900">if</span> <span style="color:#268bd2">use_kv_cache</span> <span style="color:#859900">else</span> <span style="color:#2aa198">&#34;without&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Testing </span><span style="color:#2aa198">{</span><span style="color:#268bd2">cache_status</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> KV cache...&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#859900">for</span> <span style="color:#268bd2">run</span> <span style="color:#859900">in</span> <span style="color:#cb4b16">range</span>(<span style="color:#268bd2">num_runs</span>):
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">start_time</span> = <span style="color:#268bd2">time</span>.<span style="color:#268bd2">time</span>()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#93a1a1;font-style:italic"># Generate using model.generate with appropriate use_cache setting</span>
</span></span><span style="display:flex;"><span>            <span style="color:#859900">with</span> <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">no_grad</span>():
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">output</span> = <span style="color:#268bd2">model</span>.<span style="color:#268bd2">generate</span>(
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">input_ids</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">max_new_tokens</span>=<span style="color:#268bd2">num_new_tokens</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">use_cache</span>=<span style="color:#268bd2">use_kv_cache</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">do_sample</span>=<span style="color:#859900;font-weight:bold">False</span>,  <span style="color:#93a1a1;font-style:italic"># Deterministic generation (greedy)</span>
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">pad_token_id</span>=<span style="color:#268bd2">tokenizer</span>.<span style="color:#268bd2">eos_token_id</span>
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">elapsed</span> = <span style="color:#268bd2">time</span>.<span style="color:#268bd2">time</span>() - <span style="color:#268bd2">start_time</span>
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">results</span>[<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;</span><span style="color:#2aa198">{</span><span style="color:#268bd2">cache_status</span><span style="color:#2aa198">}</span><span style="color:#2aa198">_kv_cache&#34;</span>].<span style="color:#268bd2">append</span>(<span style="color:#268bd2">elapsed</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;  Run </span><span style="color:#2aa198">{</span><span style="color:#268bd2">run</span>+<span style="color:#2aa198;font-weight:bold">1</span><span style="color:#2aa198">}</span><span style="color:#2aa198">/</span><span style="color:#2aa198">{</span><span style="color:#268bd2">num_runs</span><span style="color:#2aa198">}</span><span style="color:#2aa198">: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">elapsed</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.4f</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> seconds&#34;</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">avg_time</span> = <span style="color:#cb4b16">sum</span>(<span style="color:#268bd2">results</span>[<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;</span><span style="color:#2aa198">{</span><span style="color:#268bd2">cache_status</span><span style="color:#2aa198">}</span><span style="color:#2aa198">_kv_cache&#34;</span>]) / <span style="color:#268bd2">num_runs</span>
</span></span><span style="display:flex;"><span>        <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;Average time </span><span style="color:#2aa198">{</span><span style="color:#268bd2">cache_status</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> KV cache: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">avg_time</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.4f</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> seconds</span><span style="color:#2aa198">\n</span><span style="color:#2aa198">&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#93a1a1;font-style:italic"># Calculate speedup</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">avg_time_without_kv</span> = <span style="color:#cb4b16">sum</span>(<span style="color:#268bd2">results</span>[<span style="color:#2aa198">&#34;without_kv_cache&#34;</span>]) / <span style="color:#268bd2">num_runs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">avg_time_with_kv</span> = <span style="color:#cb4b16">sum</span>(<span style="color:#268bd2">results</span>[<span style="color:#2aa198">&#34;with_kv_cache&#34;</span>]) / <span style="color:#268bd2">num_runs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">speedup</span> = <span style="color:#268bd2">avg_time_without_kv</span> / <span style="color:#268bd2">avg_time_with_kv</span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">reduction_percentage</span> = (<span style="color:#2aa198;font-weight:bold">1</span> - <span style="color:#268bd2">avg_time_with_kv</span> / <span style="color:#268bd2">avg_time_without_kv</span>) * <span style="color:#2aa198;font-weight:bold">100</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">&#34;Results summary:&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;- Without KV cache: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">avg_time_without_kv</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.4f</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> seconds&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;- With KV cache: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">avg_time_with_kv</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.4f</span><span style="color:#2aa198">}</span><span style="color:#2aa198"> seconds&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;- Speedup factor: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">speedup</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.2f</span><span style="color:#2aa198">}</span><span style="color:#2aa198">x&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#cb4b16">print</span>(<span style="color:#2aa198">f</span><span style="color:#2aa198">&#34;- Time reduction: </span><span style="color:#2aa198">{</span><span style="color:#268bd2">reduction_percentage</span><span style="color:#2aa198">:</span><span style="color:#2aa198">.2f</span><span style="color:#2aa198">}</span><span style="color:#2aa198">%&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#859900">return</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We run <code>GPT2</code> on Google Colab with a T4 GPU. The results are as follows:</p>
<pre tabindex="0"><code>Using device: cuda
Running inference with model: gpt2
Input prompt: &#39;Hello, I&#39;m a language model&#39; (Length: 7 tokens)
Generating 1000 new tokens, averaging over 5 runs

Results summary:
- Without KV cache: 43.3307 seconds
- With KV cache: 8.3611 seconds
- Speedup factor: 5.18x
- Time reduction: 80.70%
</code></pre><h3 id="a-brief-peek-into-transformers-kv-cache-implementation">A brief peek into transformer&rsquo;s KV Cache implementation<a hidden class="anchor" aria-hidden="true" href="#a-brief-peek-into-transformers-kv-cache-implementation">#</a></h3>
<p>To better understand KV Cache, we can look at the transformer&rsquo;s KV Cache implementation.</p>
<p>Let&rsquo;s use GPT2 as an example.
The <code>GPT2Attention.forward</code> takes a <code>use_cache</code> boolean argument, it will return current KV matriices if <code>use_cache=True</code>.</p>
<div class="highlight"><div style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#93a1a1;font-style:italic">#src/transformers/models/gpt2/modeling_gpt2.py</span>
</span></span><span style="display:flex;"><span><span style="color:#859900">class</span> <span style="color:#cb4b16">GPT2Attention</span>(<span style="color:#268bd2">nn</span>.<span style="color:#268bd2">Module</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">forward</span>(...,   <span style="color:#268bd2">use_cache</span>: <span style="color:#268bd2">Optional</span>[<span style="color:#cb4b16">bool</span>] = <span style="color:#859900;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>        ...
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">query_states</span>, <span style="color:#268bd2">key_states</span>, <span style="color:#268bd2">value_states</span> = <span style="color:#268bd2">self</span>.<span style="color:#268bd2">c_attn</span>(<span style="color:#268bd2">hidden_states</span>).<span style="color:#268bd2">split</span>(<span style="color:#268bd2">self</span>.<span style="color:#268bd2">split_size</span>, <span style="color:#268bd2">dim</span>=<span style="color:#2aa198;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#859900">if</span> <span style="color:#268bd2">use_cache</span> <span style="color:#859900">is</span> <span style="color:#859900;font-weight:bold">True</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">present</span> = (<span style="color:#268bd2">key_states</span>, <span style="color:#268bd2">value_states</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#859900">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">present</span> = <span style="color:#859900;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">outputs</span> = (<span style="color:#268bd2">attn_output</span>, <span style="color:#268bd2">present</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#859900">if</span> <span style="color:#268bd2">output_attentions</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">outputs</span> += (<span style="color:#268bd2">attn_weights</span>,)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#859900">return</span> <span style="color:#268bd2">outputs</span>  <span style="color:#93a1a1;font-style:italic"># a, present, (attentions)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>GPT2Block</code> class does similar things, then <code>GPT2Model.forward</code> will output the KV matrics for all layers.</p>
<div class="highlight"><div style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#93a1a1;font-style:italic">#src/transformers/models/gpt2/modeling_gpt2.py</span>
</span></span><span style="display:flex;"><span><span style="color:#859900">class</span> <span style="color:#cb4b16">GPT2Model</span>(<span style="color:#268bd2">GPT2PreTrainedModel</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">__init__</span>(<span style="color:#268bd2">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">self</span>.<span style="color:#268bd2">h</span> = <span style="color:#268bd2">nn</span>.<span style="color:#268bd2">ModuleList</span>([<span style="color:#268bd2">GPT2Block</span>(<span style="color:#268bd2">config</span>, <span style="color:#268bd2">layer_idx</span>=<span style="color:#268bd2">i</span>) <span style="color:#859900">for</span> <span style="color:#268bd2">i</span> <span style="color:#859900">in</span> <span style="color:#cb4b16">range</span>(<span style="color:#268bd2">config</span>.<span style="color:#268bd2">num_hidden_layers</span>)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">forward</span>(..., <span style="color:#268bd2">past_key_values</span>: <span style="color:#268bd2">Optional</span>[<span style="color:#268bd2">Tuple</span>[<span style="color:#268bd2">Tuple</span>[<span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>]]] = <span style="color:#859900;font-weight:bold">None</span>,
</span></span><span style="display:flex;"><span><span style="color:#268bd2">use_cache</span>: <span style="color:#268bd2">Optional</span>[<span style="color:#cb4b16">bool</span>] = <span style="color:#859900;font-weight:bold">False</span>):
</span></span><span style="display:flex;"><span>        ...
</span></span><span style="display:flex;"><span>        <span style="color:#93a1a1;font-style:italic"># presents is used to store KV matrics for all layers.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">presents</span> = () <span style="color:#859900">if</span> <span style="color:#268bd2">use_cache</span> <span style="color:#859900">else</span> <span style="color:#859900;font-weight:bold">None</span>
</span></span><span style="display:flex;"><span>        <span style="color:#859900">for</span> <span style="color:#268bd2">i</span> <span style="color:#859900">in</span> <span style="color:#cb4b16">range</span>(<span style="color:#cb4b16">len</span>(<span style="color:#268bd2">self</span>.<span style="color:#268bd2">h</span>)):
</span></span><span style="display:flex;"><span>            <span style="color:#93a1a1;font-style:italic"># Get previous KV matrics from input.</span>
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">block</span>, <span style="color:#268bd2">layer_past</span> = <span style="color:#268bd2">self</span>.<span style="color:#268bd2">h</span>[<span style="color:#268bd2">i</span>], <span style="color:#268bd2">past_key_values</span>[<span style="color:#268bd2">i</span>]
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">outputs</span> = <span style="color:#268bd2">block</span>(<span style="color:#268bd2">input_ids</span>, <span style="color:#268bd2">layer_past</span>=<span style="color:#268bd2">layer_past</span>, <span style="color:#268bd2">use_cache</span>=<span style="color:#268bd2">use_cache</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#859900">if</span> <span style="color:#268bd2">use_cache</span> <span style="color:#859900">is</span> <span style="color:#859900;font-weight:bold">True</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">presents</span> = <span style="color:#268bd2">presents</span> + (<span style="color:#268bd2">outputs</span>[<span style="color:#2aa198;font-weight:bold">1</span>],)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#859900">return</span> <span style="color:#268bd2">BaseModelOutputWithPastAndCrossAttentions</span>(
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">last_hidden_state</span>=<span style="color:#268bd2">hidden_states</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">past_key_values</span>=<span style="color:#268bd2">presents</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">hidden_states</span>=<span style="color:#268bd2">all_hidden_states</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">attentions</span>=<span style="color:#268bd2">all_self_attentions</span>,
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">cross_attentions</span>=<span style="color:#268bd2">all_cross_attentions</span>,
</span></span><span style="display:flex;"><span>        )
</span></span></code></pre></td></tr></table>
</div>
</div><p>The KV Cache in <code>past_key_values</code> of <code>GPT2Model.forward</code> is a <code>BaseModelOutputWithPastAndCrossAttentions</code>. It&rsquo;s of shape <code>(num_layers, 2)</code>, where the first dimension corresponds to the layer index and the second dimension is <code>key</code> at index 0 and <code>value</code> at index 1. Then each tensor is of shape <code>(batch_size, num_heads, seq_len, head_dim)</code>.</p>
<p>During generation, a <code>DynamicCache</code> instance is created in <code>GenerationMixin</code>.</p>
<div class="highlight"><div style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#93a1a1;font-style:italic">#/src/transformers/src/transformers/generation/utils.py</span>
</span></span><span style="display:flex;"><span><span style="color:#859900">class</span> <span style="color:#cb4b16">GenerationMixin</span>:
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">_prepare_cache_for_generation</span>(<span style="color:#268bd2">self</span>, <span style="color:#268bd2">model_kwargs</span>: <span style="color:#268bd2">Dict</span>[<span style="color:#cb4b16">str</span>, <span style="color:#268bd2">Any</span>]):
</span></span><span style="display:flex;"><span>        ...
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">cache_name</span> = <span style="color:#2aa198">&#34;past_key_values&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">model_kwargs</span>[<span style="color:#268bd2">cache_name</span>] = <span style="color:#268bd2">DynamicCache</span>()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#93a1a1;font-style:italic">#src/transformers/cache_utils.py</span>
</span></span><span style="display:flex;"><span><span style="color:#859900">class</span> <span style="color:#cb4b16">DynamicCache</span>(<span style="color:#268bd2">Cache</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">__init__</span>(<span style="color:#268bd2">self</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">self</span>.<span style="color:#268bd2">_seen_tokens</span> = <span style="color:#2aa198;font-weight:bold">0</span>  <span style="color:#93a1a1;font-style:italic"># Used in `generate` to keep tally of how many tokens the cache has seen</span>
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>: <span style="color:#268bd2">List</span>[<span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>] = []
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">self</span>.<span style="color:#268bd2">value_cache</span>: <span style="color:#268bd2">List</span>[<span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>] = []
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">update</span>(
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">self</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">key_states</span>: <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">value_states</span>: <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">layer_idx</span>: <span style="color:#cb4b16">int</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">cache_kwargs</span>: <span style="color:#268bd2">Optional</span>[<span style="color:#268bd2">Dict</span>[<span style="color:#cb4b16">str</span>, <span style="color:#268bd2">Any</span>]] = <span style="color:#859900;font-weight:bold">None</span>,
</span></span><span style="display:flex;"><span>    ) -&gt; <span style="color:#268bd2">Tuple</span>[<span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>, <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">Tensor</span>]:
</span></span><span style="display:flex;"><span>        <span style="color:#93a1a1;font-style:italic"># Update the number of seen tokens on layer 0.</span>
</span></span><span style="display:flex;"><span>        <span style="color:#859900">if</span> <span style="color:#268bd2">layer_idx</span> == <span style="color:#2aa198;font-weight:bold">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">self</span>.<span style="color:#268bd2">_seen_tokens</span> += <span style="color:#268bd2">key_states</span>.<span style="color:#268bd2">shape</span>[-<span style="color:#2aa198;font-weight:bold">2</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#93a1a1;font-style:italic"># Update the cache</span>
</span></span><span style="display:flex;"><span>        <span style="color:#859900">if</span> <span style="color:#268bd2">key_states</span> <span style="color:#859900">is</span> <span style="color:#859900">not</span> <span style="color:#859900;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#93a1a1;font-style:italic"># Initialization phase, the layer cache not there yet.</span>
</span></span><span style="display:flex;"><span>            <span style="color:#859900">if</span> <span style="color:#cb4b16">len</span>(<span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>) &lt;= <span style="color:#268bd2">layer_idx</span>:
</span></span><span style="display:flex;"><span>                ...
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>.<span style="color:#268bd2">append</span>(<span style="color:#268bd2">key_states</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">self</span>.<span style="color:#268bd2">value_cache</span>.<span style="color:#268bd2">append</span>(<span style="color:#268bd2">value_states</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#859900">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#93a1a1;font-style:italic"># Otherwise, only append current key and value to the cache.</span>
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>[<span style="color:#268bd2">layer_idx</span>] = <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">cat</span>([<span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>[<span style="color:#268bd2">layer_idx</span>], <span style="color:#268bd2">key_states</span>], <span style="color:#268bd2">dim</span>=-<span style="color:#2aa198;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">self</span>.<span style="color:#268bd2">value_cache</span>[<span style="color:#268bd2">layer_idx</span>] = <span style="color:#268bd2">torch</span>.<span style="color:#268bd2">cat</span>([<span style="color:#268bd2">self</span>.<span style="color:#268bd2">value_cache</span>[<span style="color:#268bd2">layer_idx</span>], <span style="color:#268bd2">value_states</span>], <span style="color:#268bd2">dim</span>=-<span style="color:#2aa198;font-weight:bold">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#859900">return</span> <span style="color:#268bd2">self</span>.<span style="color:#268bd2">key_cache</span>[<span style="color:#268bd2">layer_idx</span>], <span style="color:#268bd2">self</span>.<span style="color:#268bd2">value_cache</span>[<span style="color:#268bd2">layer_idx</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#268bd2">@classmethod</span>
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">from_legacy_cache</span>(<span style="color:#268bd2">cls</span>, <span style="color:#268bd2">past_key_values</span>: <span style="color:#268bd2">Optional</span>[<span style="color:#268bd2">Tuple</span>[<span style="color:#268bd2">Tuple</span>[<span style="color:#268bd2">torch</span>.<span style="color:#268bd2">FloatTensor</span>]]] = <span style="color:#859900;font-weight:bold">None</span>) -&gt; <span style="color:#2aa198">&#34;DynamicCache&#34;</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#2aa198">&#34;&#34;&#34;Converts a cache in the legacy cache format into an equivalent `DynamicCache`. &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#268bd2">cache</span> = <span style="color:#268bd2">cls</span>()
</span></span><span style="display:flex;"><span>        <span style="color:#859900">if</span> <span style="color:#268bd2">past_key_values</span> <span style="color:#859900">is</span> <span style="color:#859900">not</span> <span style="color:#859900;font-weight:bold">None</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#859900">for</span> <span style="color:#268bd2">layer_idx</span> <span style="color:#859900">in</span> <span style="color:#cb4b16">range</span>(<span style="color:#cb4b16">len</span>(<span style="color:#268bd2">past_key_values</span>)):
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">key_states</span>, <span style="color:#268bd2">value_states</span> = <span style="color:#268bd2">past_key_values</span>[<span style="color:#268bd2">layer_idx</span>]
</span></span><span style="display:flex;"><span>                <span style="color:#268bd2">cache</span>.<span style="color:#268bd2">update</span>(<span style="color:#268bd2">key_states</span>, <span style="color:#268bd2">value_states</span>, <span style="color:#268bd2">layer_idx</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#859900">return</span> <span style="color:#268bd2">cache</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then the KV Cache is loaded and used for generation in <code>_sample</code>:</p>
<div class="highlight"><div style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#586e75;background-color:#eee8d5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#268bd2">src</span>/<span style="color:#268bd2">transformers</span>/<span style="color:#268bd2">generation</span>/<span style="color:#268bd2">utils</span>.<span style="color:#268bd2">py</span>
</span></span><span style="display:flex;"><span><span style="color:#859900">class</span> <span style="color:#cb4b16">GenerationMixin</span>:
</span></span><span style="display:flex;"><span>    ...
</span></span><span style="display:flex;"><span>    <span style="color:#859900">def</span> <span style="color:#268bd2">_sample</span>(<span style="color:#268bd2">self</span>, ...):
</span></span><span style="display:flex;"><span>        ...
</span></span><span style="display:flex;"><span>        <span style="color:#859900">while</span> <span style="color:#268bd2">self</span>.<span style="color:#268bd2">_has_unfinished_sequences</span>():
</span></span><span style="display:flex;"><span>            <span style="color:#93a1a1;font-style:italic"># Prepare KV Cache is in prepare_inputs_for_generation</span>
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">model_inputs</span> = <span style="color:#268bd2">self</span>.<span style="color:#268bd2">prepare_inputs_for_generation</span>(<span style="color:#268bd2">input_ids</span>, **<span style="color:#268bd2">model_kwargs</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#268bd2">outputs</span> = <span style="color:#268bd2">model_forward</span>(**<span style="color:#268bd2">model_inputs</span>, <span style="color:#268bd2">return_dict</span>=<span style="color:#859900;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>        ...
</span></span><span style="display:flex;"><span>        <span style="color:#859900">return</span> <span style="color:#268bd2">GenerateDecoderOnlyOutput</span>(
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">sequences</span>=<span style="color:#268bd2">input_ids</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">scores</span>=<span style="color:#268bd2">scores</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">logits</span>=<span style="color:#268bd2">raw_logits</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">attentions</span>=<span style="color:#268bd2">decoder_attentions</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">hidden_states</span>=<span style="color:#268bd2">decoder_hidden_states</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#268bd2">past_key_values</span>=<span style="color:#268bd2">model_kwargs</span>.<span style="color:#268bd2">get</span>(<span style="color:#2aa198">&#34;past_key_values&#34;</span>),
</span></span><span style="display:flex;"><span>                )
</span></span></code></pre></td></tr></table>
</div>
</div>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/vllm/">Vllm</a></li>
      <li><a href="http://localhost:1313/tags/kv-cache/">KV Cache</a></li>
      <li><a href="http://localhost:1313/tags/transformer/">Transformer</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://localhost:1313/posts/rl-intro/">
    <span class="title">« Prev</span>
    <br>
    <span>Introduction to Reinforcement Learning with Cliff Walking</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on x"
            href="https://x.com/intent/tweet/?text=KV%20Cache%20Explained&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f&amp;hashtags=vllm%2cKVCache%2ctransformer">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f&amp;title=KV%20Cache%20Explained&amp;summary=KV%20Cache%20Explained&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f&title=KV%20Cache%20Explained">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on whatsapp"
            href="https://api.whatsapp.com/send?text=KV%20Cache%20Explained%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on telegram"
            href="https://telegram.me/share/url?text=KV%20Cache%20Explained&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share KV Cache Explained on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=KV%20Cache%20Explained&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fkv-cache%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Log(hx)</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
